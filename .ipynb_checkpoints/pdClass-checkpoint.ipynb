{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AEspeech import AEspeech\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "PATH=os.getcwd()\n",
    "# wav_path=PATH+\"/tedx_spanish_corpus/speech/test/\"\n",
    "pd_path=PATH+\"/pdSpanish/speech/pataka/pd/\"\n",
    "hc_path=PATH+\"/pdSpanish/speech/pataka/hc/\"\n",
    "pd_files=[name for name in os.listdir(pd_path) if '.wav' in name]\n",
    "hc_files=[name for name in os.listdir(hc_path) if '.wav' in name]\n",
    "# wav_file=wav_path+'/'+wav_files[0]\n",
    "\n",
    "model=\"CAE\"\n",
    "units=256\n",
    "rep=\"spec\"\n",
    "\n",
    "aespeech=AEspeech(model=model,units=units,rep=rep) # load the pretrained CAE with 1024 units\n",
    "# mat_spec=aespeech.compute_spectrograms(wav_file) # compute the decoded spectrograms from the autoencoder\n",
    "# print(mat_spec.size())\n",
    "#     aespeech.show_spectrograms(mat_spec)\n",
    "\n",
    "# bottle=aespeech.compute_bottleneck_features(wav_file)   # compute the bottleneck feaatures from a wav file\n",
    "# print(bottle.shape)\n",
    "\n",
    "# error=aespeech.compute_rec_error_features(wav_file) # compute the reconstruction error features from a wav file\n",
    "# print(error.shape)\n",
    "\n",
    "# wav_directory=PATH+\"../tedx_spanish_corpus/speech/\"\n",
    "pd=aespeech.compute_dynamic_features(pd_path)\n",
    "hc=aespeech.compute_dynamic_features(hc_path)# compute the bottleneck and error-based features from a directory with wav files inside \n",
    "                                                      #(dynamic: one feture vector for each 500 ms frame)\n",
    "# print(df)\n",
    "# print(pd[\"bottleneck\"].shape)\n",
    "# print(df[\"error\"].shape)\n",
    "# print(df[\"wav_file\"].shape)\n",
    "# print(df[\"frame\"].shape)\n",
    "\n",
    "# df1, df2=aespeech.compute_global_features(wav_path)  # compute the bottleneck and error-based features from a directory with wav files inside \n",
    "#                                                           #(static: one feture vector per utterance)\n",
    "# print(df1)\n",
    "# print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spks=pd_files+hc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "pdCurrs=[pd_files[idx] for idx in random.sample(range(0,len(pd_files)),5)]\n",
    "hcCurrs=[hc_files[idx] for idx in random.sample(range(0,len(hc_files)),5)]\n",
    "pd_files=[pd for pd in pd_files if pd not in pdCurrs]\n",
    "hc_files=[hc for hc in hc_files if hc not in hcCurrs]\n",
    "\n",
    "pdIds=[spks.index(pdCurr) for pdCurr in pdCurrs]\n",
    "hcIds=[spks.index(hcCurr) for hcCurr in hcCurrs]\n",
    "testDict={spk:{num[i]:{'feat':[]} for num in zip(pdIds,hcIds)} for i,spk in enumerate(['pd','hc'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 9 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ee0a941793c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhc_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2619\u001b[0m     \"\"\"\n\u001b[0;32m   2620\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[1;32m-> 2621\u001b[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 9 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "int(np.max(len(pd_files)//5,len(hc_files)//5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDict['pd'][24],testDict['pd'][47]=1,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pd': {24: 1, 39: {'feat': []}, 19: {'feat': []}, 20: {'feat': []}, 47: 10},\n",
       " 'hc': {76: {'feat': []},\n",
       "  50: {'feat': []},\n",
       "  78: {'feat': []},\n",
       "  84: {'feat': []},\n",
       "  53: {'feat': []}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {key:{} for spk in ['pd','hc'] for key in testDict[spk].keys()}\n",
    "testResults=pd.DataFrame(columns=np.arange(int(np.max([50/5,50/5]))))\n",
    "\n",
    "testDict={spk:{num[i]:{'feats':[]} for num in zip(pdIds,hcIds)} for i,spk in enumerate(['pd','hc'])}\n",
    "testResults[0]={'test_loss':0, 'test_acc':0, 'tstSpk_data':{key:{} for spk in ['pd','hc'] for key in testDict[spk].keys()}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in testDict['pd'].keys():\n",
    "    if not testDict['pd'][key]['feat']:\n",
    "        print(testDict['pd'][key]['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds=[name for name in os.listdir(pd_path) if '.wav' in name]\n",
    "hcs=[name for name in os.listdir(hc_path) if '.wav' in name]\n",
    "pds.sort()\n",
    "hcs.sort()\n",
    "len(pds)\n",
    "itr=0\n",
    "\n",
    "testBns=pd['error'][np.where(pd['wav_file']==pds[itr])]\n",
    "trainBns=pd['error'][np.where(pd['wav_file']!=pds[itr])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,1,1,0,0,0,0]\n",
    "np.count_nonzero(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_vecs=np.zeros((len(pd['wav_file'][np.where(pd['wav_file']==pds[0])]),256+128))\n",
    "# for ii,wav in enumerate(pd['wav_file'][np.where(pd['wav_file']==pds[0])]):  \n",
    "bns=pd['bottleneck'][np.where(pd['wav_file']==pds[itr])]\n",
    "errs=pd['error'][np.where(pd['wav_file']==pds[itr])]\n",
    "feat_vecs=np.concatenate((bns,errs),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_vecs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((np.ones((feat_vecs.shape[0])),np.ones((feat_vecs.shape[0])))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdRange=np.arange(0,0+5)\n",
    "hcRange=np.arange(50,50+5)\n",
    "np.concatenate((pdRange,hcRange))\n",
    "# ts={spk:{num[i]:{'bottleneck':[], 'error':[]} for num in zip(pdRange,hcRange)} for i,spk in enumerate(['pd','hc'])}\n",
    "# ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=PATH+\"/deepClassModels/feats/\"    \n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "pd_feat_vecs=np.zeros((len(pd['wav_file']),pd['error'].shape[1]+pd['bottleneck'].shape[1]))\n",
    "pd_y=np.ones((len(pd['wav_file'])))\n",
    "pd_y=np.zeros((len(pd['wav_file'])))   \n",
    "\n",
    "for itr,wav in enumerate(pd['wav_file']):    \n",
    "    pd_feat_vecs[itr,:]=np.concatenate((pd['error'][itr], pd['bottleneck'][itr]),axis=0)\n",
    "    \n",
    "#     spkID=pd['wav_file'][value].split('_')[0]\n",
    "#     fr=str(pd['frame'][value])\n",
    "#     np.save(save_path+'/pd_'+spkID+'_'+fr+'.npy', feat_vec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_feat_vecs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
