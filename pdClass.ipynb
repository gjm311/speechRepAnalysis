{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AEspeech import AEspeech\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "b=['a','b','c']\n",
    "\n",
    "c=[e for e in a if e>1 and b[e-1]=='b']\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "PATH=os.getcwd()\n",
    "# wav_path=PATH+\"/tedx_spanish_corpus/speech/test/\"\n",
    "pd_path=PATH+\"/pdSpanish/speech/pataka/pd/\"\n",
    "hc_path=PATH+\"/pdSpanish/speech/pataka/hc/\"\n",
    "pd_files=[name for name in os.listdir(pd_path) if '.wav' in name]\n",
    "hc_files=[name for name in os.listdir(hc_path) if '.wav' in name]\n",
    "# wav_file=wav_path+'/'+wav_files[0]\n",
    "\n",
    "model=\"CAE\"\n",
    "units=256\n",
    "rep=\"spec\"\n",
    "\n",
    "aespeech=AEspeech(model=model,units=units,rep=rep) # load the pretrained CAE with 1024 units\n",
    "# mat_spec=aespeech.compute_spectrograms(wav_file) # compute the decoded spectrograms from the autoencoder\n",
    "# print(mat_spec.size())\n",
    "#     aespeech.show_spectrograms(mat_spec)\n",
    "\n",
    "# bottle=aespeech.compute_bottleneck_features(wav_file)   # compute the bottleneck feaatures from a wav file\n",
    "# print(bottle.shape)\n",
    "\n",
    "# error=aespeech.compute_rec_error_features(wav_file) # compute the reconstruction error features from a wav file\n",
    "# print(error.shape)\n",
    "\n",
    "# wav_directory=PATH+\"../tedx_spanish_corpus/speech/\"\n",
    "pd=aespeech.compute_dynamic_features(pd_path)\n",
    "hc=aespeech.compute_dynamic_features(hc_path)# compute the bottleneck and error-based features from a directory with wav files inside \n",
    "                                                      #(dynamic: one feture vector for each 500 ms frame)\n",
    "# print(df)\n",
    "# print(pd[\"bottleneck\"].shape)\n",
    "# print(df[\"error\"].shape)\n",
    "# print(df[\"wav_file\"].shape)\n",
    "# print(df[\"frame\"].shape)\n",
    "\n",
    "# df1, df2=aespeech.compute_global_features(wav_path)  # compute the bottleneck and error-based features from a directory with wav files inside \n",
    "#                                                           #(static: one feture vector per utterance)\n",
    "# print(df1)\n",
    "# print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spks=pd_files+hc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "pdCurrs=[pd_files[idx] for idx in random.sample(range(0,len(pd_files)),5)]\n",
    "hcCurrs=[hc_files[idx] for idx in random.sample(range(0,len(hc_files)),5)]\n",
    "pd_files=[pd for pd in pd_files if pd not in pdCurrs]\n",
    "hc_files=[hc for hc in hc_files if hc not in hcCurrs]\n",
    "\n",
    "pdIds=[spks.index(pdCurr) for pdCurr in pdCurrs]\n",
    "hcIds=[spks.index(hcCurr) for hcCurr in hcCurrs]\n",
    "testDict={spk:{num[i]:{'feat':[]} for num in zip(pdIds,hcIds)} for i,spk in enumerate(['pd','hc'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDict['pd'][24],testDict['pd'][47]=1,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pd': {38: {'feat': []},\n",
       "  37: {'feat': []},\n",
       "  42: {'feat': []},\n",
       "  10: {'feat': []},\n",
       "  44: {'feat': []},\n",
       "  24: 1,\n",
       "  47: 10},\n",
       " 'hc': {50: {'feat': []},\n",
       "  79: {'feat': []},\n",
       "  51: {'feat': []},\n",
       "  71: {'feat': []},\n",
       "  77: {'feat': []}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {key:{} for spk in ['pd','hc'] for key in testDict[spk].keys()}\n",
    "testResults=pd.DataFrame(index=np.arange(int(np.max([50/5,50/5]))),columns=np.arange(1))\n",
    "\n",
    "testDict={spk:{num[i]:{'feats':[]} for num in zip(pdIds,hcIds)} for i,spk in enumerate(['pd','hc'])}\n",
    "testResults.iloc[0]=[{'test_loss':0, 'test_acc':0, 'tstSpk_data':{key:{} for spk in ['pd','hc'] for key in testDict[spk].keys()}}]\n",
    "testResults.to_pickle(PATH+\"/dnnTrainResults.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0,\n",
       " 'test_acc': 0,\n",
       " 'tstSpk_data': {38: {},\n",
       "  37: {},\n",
       "  42: {},\n",
       "  10: {},\n",
       "  44: {},\n",
       "  50: {},\n",
       "  79: {},\n",
       "  51: {},\n",
       "  71: {},\n",
       "  77: {}}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testResults.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{'test_loss': 0, 'test_acc': 0, 'tstSpk_data':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0    1    2    3    4    5  \\\n",
       "0  {'test_loss': 0, 'test_acc': 0, 'tstSpk_data':...  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "     6    7    8    9  \n",
       "0  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRes=pd.read_pickle(PATH+\"/dnnTrainResults.pkl\")\n",
    "testRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in testDict['pd'].keys():\n",
    "    if not testDict['pd'][key]['feat']:\n",
    "        print(testDict['pd'][key]['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds=[name for name in os.listdir(pd_path) if '.wav' in name]\n",
    "hcs=[name for name in os.listdir(hc_path) if '.wav' in name]\n",
    "pds.sort()\n",
    "hcs.sort()\n",
    "len(pds)\n",
    "itr=0\n",
    "\n",
    "testBns=pd['error'][np.where(pd['wav_file']==pds[itr])]\n",
    "trainBns=pd['error'][np.where(pd['wav_file']!=pds[itr])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,1,1,0,0,0,0]\n",
    "np.count_nonzero(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_vecs=np.zeros((len(pd['wav_file'][np.where(pd['wav_file']==pds[0])]),256+128))\n",
    "# for ii,wav in enumerate(pd['wav_file'][np.where(pd['wav_file']==pds[0])]):  \n",
    "bns=pd['bottleneck'][np.where(pd['wav_file']==pds[itr])]\n",
    "errs=pd['error'][np.where(pd['wav_file']==pds[itr])]\n",
    "feat_vecs=np.concatenate((bns,errs),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_vecs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((np.ones((feat_vecs.shape[0])),np.ones((feat_vecs.shape[0])))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdRange=np.arange(0,0+5)\n",
    "hcRange=np.arange(50,50+5)\n",
    "np.concatenate((pdRange,hcRange))\n",
    "# ts={spk:{num[i]:{'bottleneck':[], 'error':[]} for num in zip(pdRange,hcRange)} for i,spk in enumerate(['pd','hc'])}\n",
    "# ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=PATH+\"/deepClassModels/feats/\"    \n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "pd_feat_vecs=np.zeros((len(pd['wav_file']),pd['error'].shape[1]+pd['bottleneck'].shape[1]))\n",
    "pd_y=np.ones((len(pd['wav_file'])))\n",
    "pd_y=np.zeros((len(pd['wav_file'])))   \n",
    "\n",
    "for itr,wav in enumerate(pd['wav_file']):    \n",
    "    pd_feat_vecs[itr,:]=np.concatenate((pd['error'][itr], pd['bottleneck'][itr]),axis=0)\n",
    "    \n",
    "#     spkID=pd['wav_file'][value].split('_')[0]\n",
    "#     fr=str(pd['frame'][value])\n",
    "#     np.save(save_path+'/pd_'+spkID+'_'+fr+'.npy', feat_vec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_feat_vecs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
